# Amazon Web Services

## Aws Instance Metadata Service (IMDS)

### Overview

It’s a service that has an EC2 instance’s metadata. The metadata service stores information such as:

* `ami-id`:  An operating system id that might be googleable
* Private IP address
* Instance type: number of cores, memory, etc.
* Amazon region

The Instance Metadata Service (IMDS) can be configured to use either version 1 (IMDSv1) or version 2 ([IMDSv2](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html)). When IMDSv1 is used, then the metadata service **does not require authentication** and can therefore be accessed using **SSRF**. IMDS is available in the EC2 container's private network, at http://169.254.169.254.

_Note: ECS has a Task Metadata endpoint at http://169.254.170.2._&#x20;

### Exploitation

If there’s an open HTTP proxy running on an AWS EC2 instance, then you could query the metadata service from there and get a response back.&#x20;

Let's examine an exploitation example with an open HTTP proxy. Through the proxy, you can make a request to `http://169.254.169.254/path/to/resource` and get a response back.

_Note: IMDS shows directory listings. You can start by querying `http://169.254.169.254/` to get a list of additional things you can query, and go from there._

The IMDS service contains a lot of useless stuff, for exploitation, but there are also a few gems in there.&#x20;

#### User data script

For example, you might get a `user-data` script. This is a startup script that’s written for the automation of installing and configuring the instance. The startup script might contain valuable credentials:&#x20;

* Code repositories
* Private and public keys for accessing that repo&#x20;
* API keys)

Endpoint: `http://169.254.169.254/latest/user-data`

_Note: Putting anything valuable or secret in the `user-data` script is bad practice. More commonly, secrets are in environment variables, which are loaded into the EC2 container._

Instance profiles (credentials attached to a specific EC2 instance, used to connect to other services) are stored in the metadata service, and you can read it to get the creds attached to this instance, doing something like curl http://169.254.169.254/latest/meta-data/iam/security-credentials/ to get the list of roles and curl http://169.254.169.254/latest/meta-data/iam/security-credentials/ You can dump the credentials of that role.

Using those creds and nimbostratus, you can test all services and see which ones you can access. Note that this is bruteforced and you might not find the full permission set (for example access to a specific s3 bucket).

## AWS user-data script

This passes in stuff your AWS EC2 instance needs to function (like your AWS credentials, for example). You can access it from the metadata service.

Putting the credentials there hardcoded, in plaintext, isn’t that safe, because user-data scripts are readable through the metadata service. It’s safer to put a decryption key there, and retrieve the encrypted data either from a public HTTPS link (which expires), or from the machine itself, if you’ve burned the credentials into the machine.

## Amazon SQS

If in the permissions list you see listQueues as access, then that’s a function in SQS api (SQS is a simple queue service for messages between software components). It means you can write and read the SQS queue.

There might be a serializer like celery in between the SQS that handles serialization and deserialization between the EC2 and the workers that consume the SQS messages. Celery for example has the pickle serializer, which is inherently insecure. And you get RCE.

If you have RCE on a machine, like a worker that uses celery, then it will also have credentials that you can dump. And its permissions may be high if it’s misconfigured. In that example, the creds were hardcoded.

Also in that example, the celery worker was also running mySQL that was keeping track of the tasks that were being completed. The creds for it were in the celery config file. Nothing that interesting though.

## Identity and Access Management (IAM)

You use IAM to manage users, groups, roles, permissions, api keys. If you get a user with iam\* permissions (like misconfigured celery worker or some other thing), then you can create a user with root permissions.

If you have high permissions to the RDS api, then you could for example create a backup of the database (using snapshot and restore) and therefore get all the db data. It’s automated in nimbostratus

## Pivoting using misconfigured IAM

I had a case where all APIs (even test apis with weak protection) had the same IAM role (which provided strong permissions). So you could easily pivot from the test env to live.

If there’s one ECR for all environments, then the prelive env developer can upload his own images. Depending on how images are fetched and run, he might be able to hijack the live api.

## AWS S3

Unauthenticated bucket access - authenticate your aws account by doing aws configure, and see if you can access the bucket with aws s3 ls . If they set it to “authenticated users only”, then any authenticated user will be able to log in.

The AWS Extender Burpsuite plugin will cover trying out all actions which can be permitted on an S3 bucket.
